{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RandomForest.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "fMwZe2ZtnFqC"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "import math\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import classification_report\n",
        "from random import seed\n",
        "from random import randrange"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VO0KEC51vBTw",
        "outputId": "f4389d5a-d25b-49db-9dbf-569d8de89a31"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#the dataset aims to predict the whether a given banknote is authentic given a number of measures taken from a photograph. \n",
        "#it is a binary classification problem where 0 is the label for an authentic banknote while 1 for a fake one.\n",
        "banknoteData = pd.read_csv('/content/drive/MyDrive/MachineLearning/datasets/data_banknote_authentication.csv')\n",
        "banknoteData.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "wNTWJzz6vCCG",
        "outputId": "932a4eb4-78c0-4ac2-8cf4-df59a67ca87e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Variance of Wavelet Transformed image  \\\n",
              "0                                3.62160   \n",
              "1                                4.54590   \n",
              "2                                3.86600   \n",
              "3                                3.45660   \n",
              "4                                0.32924   \n",
              "\n",
              "   Skewness of Wavelet Transformed image  \\\n",
              "0                                 8.6661   \n",
              "1                                 8.1674   \n",
              "2                                -2.6383   \n",
              "3                                 9.5228   \n",
              "4                                -4.4552   \n",
              "\n",
              "   Kurtosis of Wavelet Transformed image  Entropy of image  Class  \n",
              "0                                -2.8073          -0.44699      0  \n",
              "1                                -2.4586          -1.46210      0  \n",
              "2                                 1.9242           0.10645      0  \n",
              "3                                -4.0112          -3.59440      0  \n",
              "4                                 4.5718          -0.98880      0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-364114ee-30b3-4109-b762-5168f234fbc5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Variance of Wavelet Transformed image</th>\n",
              "      <th>Skewness of Wavelet Transformed image</th>\n",
              "      <th>Kurtosis of Wavelet Transformed image</th>\n",
              "      <th>Entropy of image</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3.62160</td>\n",
              "      <td>8.6661</td>\n",
              "      <td>-2.8073</td>\n",
              "      <td>-0.44699</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.54590</td>\n",
              "      <td>8.1674</td>\n",
              "      <td>-2.4586</td>\n",
              "      <td>-1.46210</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3.86600</td>\n",
              "      <td>-2.6383</td>\n",
              "      <td>1.9242</td>\n",
              "      <td>0.10645</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3.45660</td>\n",
              "      <td>9.5228</td>\n",
              "      <td>-4.0112</td>\n",
              "      <td>-3.59440</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.32924</td>\n",
              "      <td>-4.4552</td>\n",
              "      <td>4.5718</td>\n",
              "      <td>-0.98880</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-364114ee-30b3-4109-b762-5168f234fbc5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-364114ee-30b3-4109-b762-5168f234fbc5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-364114ee-30b3-4109-b762-5168f234fbc5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = banknoteData.iloc[:,:-1].values\n",
        "y = (banknoteData.iloc[:,-1].values).reshape(-1,1)"
      ],
      "metadata": {
        "id": "D3APUFKRxKTx"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2)\n",
        "print('n samples in Train set: ', len(X_train))\n",
        "print('n samples in Test set: ', len(X_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U_fgkdBJPiY1",
        "outputId": "59589f0e-bd83-415e-e041-054a8fa03410"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "n samples in Train set:  1097\n",
            "n samples in Test set:  275\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Random Forest from scratch#"
      ],
      "metadata": {
        "id": "-Vnju8XivXyd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*random forest relies on the bagging methods which is an ensembling technique. The idea is to divide the training dataset in subsets and then train several decision trees separately, one for each subset.Once all predictors are trained, the ensemble can make a prediction for a new instance by aggregating the predictions of all predictors.\n",
        "The term bagging stands for bootstrap aggregation.\n",
        "The bagging method is characterized by the fact that the sampling is performed with replacement, i.e.the same row (set of input vatriables with the corresponding input) may be chosen and added to the sample more than once.*\n"
      ],
      "metadata": {
        "id": "skXLDtRiwgHt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "reference: https://carbonati.github.io/posts/random-forests-from-scratch/#:~:text=Random%20forests%20are%20essentially%20a,us%20with%20a%20powerful%20classifier."
      ],
      "metadata": {
        "id": "MdnvKqH_tJtm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#entropy loss: it measures the uncertainty (inpurity). It is minimized when all samples in a node belong to the same class\n",
        "#it is maximized when we have uniform class distribution\n",
        "\n",
        "#p is the probability P(X=1) that a banknote is a true one\n",
        "def entropy (p):\n",
        "  if p==0 or p==1: entropy = 0\n",
        "  else:\n",
        "    #- (p * np.log2(p) + (1 - p) * np.log2(1-p))\n",
        "    entropy = -(p * np.log2(p) + (1 - p) * np.log2(1-p))\n",
        "    #-p*np.log2(p)-(1-p)*np.log2(1-p)\n",
        "  return entropy\n",
        "\n",
        "#after a slit we compare the entropy before the latter and after it. The measure we get is the information gain. \n",
        "#infomation gain reveals how much information when splitting a node at a particular value\n",
        "#the idea is to split a node with the value that maximizes the information gain(IG)\n",
        "\n",
        "#IG function takes of the classes from the left and right child and returns the information gain of that particular split.\n",
        "def IG(left_child,right_child):\n",
        "\n",
        "  parent = left_child+right_child\n",
        "  N_p = len(parent)\n",
        "  N_left = len(left_child)\n",
        "  N_right = len(right_child)\n",
        "\n",
        "  if len(parent) > 0:\n",
        "    #.count(1) counts the number of elements with class=1\n",
        "    #in this phase p for parent,left and right child is computed\n",
        "    p_parent = parent.count(1)/N_p\n",
        "  else: p_parent = 0\n",
        "\n",
        "  if len(left_child) > 0:\n",
        "    p_lf_c = left_child.count(1)/N_left\n",
        "  else: p_lf_c = 0\n",
        "\n",
        "  if len(right_child) > 0:\n",
        "    p_rt_c = right_child.count(1)/N_right\n",
        "  else: p_rt_c = 0\n",
        "\n",
        "  #compute entropy for parent and left and right child\n",
        "  ID_p = entropy(p_parent)\n",
        "  ID_left = entropy(p_lf_c)\n",
        "  ID_right = entropy(p_rt_c)\n",
        "  #information gain \n",
        "  IG = ID_p - (N_left/N_p)*ID_left -(N_right/N_p)*ID_right\n",
        "  return IG "
      ],
      "metadata": {
        "id": "SvdRHaPlC-JO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#each decision tree is trained on a bootstrapped subset coming from our dataset. \n",
        "# considering that the dataset has n samples, bootstrapping is the process of sampling n point with replacement (i.e., some obsverations in our dataset will be selected more than once and some won't be selected at all)\n",
        "\n",
        "def bootstrap(X,y):\n",
        "  #takes random indices from the original train frame\n",
        "  bootstrap_idxs = list(np.random.choice(range(X.shape[0]),X.shape[0], replace = True))\n",
        "  oob_idxs = []\n",
        "  for i in range(X.shape[0]):\n",
        "    if i not in bootstrap_idxs:\n",
        "       oob_idxs.append(i)\n",
        "  #select the samples of the corresponding indices\n",
        "  X_bootstrap = X[bootstrap_idxs]\n",
        "  y_bootstrap = y[bootstrap_idxs]\n",
        "  \n",
        "  X_oob = X[oob_idxs]\n",
        "  y_oob = y[oob_idxs]\n",
        "\n",
        "  return X_bootstrap, y_bootstrap, X_oob, y_oob\n",
        "\n",
        "#X_bootstrap, y_bootstrap, X_oob, y_oob = bootstrap(X_train,y_train)\n",
        "\n",
        "#OOB = out-of-bag error estimate: the remaing samples that were not selected to build a parcticular tree.\n",
        "#once we've built our tree with the n bootstrapped observations we can test each x_i that was left out and compute the mean prediction error from those samples.\n",
        "#for each tree we can compute an OOB score  and take the average of all those scores to get an estimate for how accurate our model performs\n",
        "\n",
        "def OOB(tree, X, y):\n",
        "  mis_label = 0\n",
        "  for i in range(X.shape[0]):\n",
        "    pred = single_tree_pred(tree, X[i])\n",
        "    if pred != y[i]:\n",
        "      mis_label += 1\n",
        "  return mis_label / len(X)"
      ],
      "metadata": {
        "id": "XIChUptKL2fA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_split_point(X_b,y_b,max_features):\n",
        "  fts_list = list()\n",
        "  n_features = len(X_b[0])\n",
        "  \n",
        "  #select n features at random \n",
        "  while len(fts_list) <= max_features:\n",
        "    feature_idx = random.sample(range(n_features),1)\n",
        "    if feature_idx not in fts_list:\n",
        "        fts_list.extend(feature_idx)\n",
        "  \n",
        "  #for each feature selected, iterate through each value in the bootstrapped dataset and compute the information gain\n",
        "  best_IG=-999\n",
        "  node = None\n",
        "  for idx in fts_list:\n",
        "    for split_point in X_b[:,idx]:\n",
        "      left_child = {'X_bootstrap': [], 'y_bootstrap': []}\n",
        "      right_child = {'X_bootstrap': [], 'y_bootstrap': []}\n",
        "\n",
        "      # split children for continuous variables\n",
        "      if type(split_point) in [int, float]:\n",
        "        for i, val in enumerate(X_b[:,idx]):\n",
        "          if val <= split_point:\n",
        "            left_child['X_bootstrap'].append(X_b[i])\n",
        "            left_child['y_bootstrap'].append(y_b[i])\n",
        "          else:\n",
        "            right_child['X_bootstrap'].append(X_b[i])\n",
        "            right_child['y_bootstrap'].append(y_b[i])\n",
        "      # split children for categoric variables\n",
        "      else:\n",
        "        for j, value in enumerate(X_b[:,idx]):\n",
        "          if value == split_point:\n",
        "            left_child['X_bootstrap'].append(X_b[j])\n",
        "            left_child['y_bootstrap'].append(y_b[j])\n",
        "          else:\n",
        "            right_child['X_bootstrap'].append(X_b[j])\n",
        "            right_child['y_bootstrap'].append(y_b[j])\n",
        "\n",
        "      split_IG = IG(left_child['y_bootstrap'], right_child['y_bootstrap'])\n",
        "      #Return a dictionary from the value that gives the highest information gain\n",
        "      if split_IG>best_IG:\n",
        "        best_IG = split_IG\n",
        "        left_child['X_bootstrap'] = np.array(left_child['X_bootstrap'])\n",
        "        right_child['X_bootstrap'] = np.array(right_child['X_bootstrap'])\n",
        "        node = {'information_gain': split_IG,\n",
        "                'left_child': left_child,\n",
        "                'right_child': right_child,\n",
        "                'split_point': split_point,\n",
        "                'feature_idx': idx}\n",
        "\n",
        "\n",
        "  return node"
      ],
      "metadata": {
        "id": "fkVC6Gb3lL9q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def terminal_node(node):\n",
        "  y_b = node['y_bootstrap']\n",
        "  pred = max(y_b, key=y_b.count)\n",
        "  return pred\n",
        "\n",
        "def split_node(node, max_features, min_samples_split, max_depth, depth):\n",
        "  #remove left and right child from the original dictionary\n",
        "  left_child = node['left_child']\n",
        "  right_child = node['right_child']\n",
        "  del(node['left_child'])\n",
        "  del(node['right_child'])\n",
        "\n",
        "  #check if the children has no observations. \n",
        "  #If one of the children is entirely empty this ultimately means that the best split in the data for that node was unable to differentiate the 2 classes \n",
        "  #therefore, its best to call terminal_node and return the tree. terminal_node returns the class with the highest counts at the current node.\n",
        "  if len(left_child['y_bootstrap']) == 0 or len(right_child['y_bootstrap']) == 0:\n",
        "    empty_child = {'y_bootstrap': left_child['y_bootstrap']+right_child['y_bootstrap']}\n",
        "    node['left_split'] = terminal_node(empty_child)\n",
        "    node['right_split'] = terminal_node(empty_child)\n",
        "    return\n",
        "\n",
        "  #if the current depth = max_depth then create a terminal node and return the tree\n",
        "  if depth >= max_depth:\n",
        "    node['left_split'] = terminal_node(left_child)\n",
        "    node['right_split'] = terminal_node(right_child)\n",
        "    return node\n",
        "\n",
        "  #check if min_split is greater than the number of observation in the left child at the current node in order to make a split\n",
        "  if len(left_child['X_bootstrap']) <= min_samples_split:\n",
        "    node['left_split'] = node['right_split'] = terminal_node(left_child)\n",
        "  else:\n",
        "    node['left_split'] = get_split_point(left_child['X_bootstrap'], left_child['y_bootstrap'], max_features)\n",
        "    split_node(node['left_split'], max_depth, min_samples_split, max_depth, depth+1)\n",
        "  \n",
        "  if len(right_child['X_bootstrap']) <= min_samples_split:\n",
        "    node['right_split'] = node['left_split'] = terminal_node(right_child)\n",
        "  else:\n",
        "    node['right_split'] = get_split_point(right_child['X_bootstrap'], right_child['y_bootstrap'], max_features)\n",
        "    split_node(node['right_split'], max_features, min_samples_split, max_depth, depth+1)\n"
      ],
      "metadata": {
        "id": "Meflg5wYxgkY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#definition of a single tree\n",
        "def single_tree(X_b, y_b, max_depth, min_samples_split, max_features):\n",
        "  root_node = get_split_point(X_b, y_b, max_features)\n",
        "  split_node(root_node, max_features, min_samples_split, max_depth, 1)\n",
        "  return root_node\n",
        "\n",
        "#random forest paramters\n",
        "#n_tree = number of tree in the model\n",
        "#max_features= n of features to consider when looking for the best split\n",
        "#max_depth = the max depth of a tree\n",
        "#min_sample_split=  the min n. of samples required to split an internal node\n",
        "def random_forest(X,y, n_tree, max_features, max_depth, min_samples_split):\n",
        "  tree_ls = list()\n",
        "  oob_ls = list()\n",
        "  for i in range(n_tree):\n",
        "    X_bootstrap, y_bootstrap, X_oob, y_oob = bootstrap(X, y)\n",
        "    tree = single_tree(X_bootstrap, y_bootstrap, max_features, max_depth, min_samples_split)\n",
        "    tree_ls.append(tree)\n",
        "    oob_error = OOB(tree, X_oob, y_oob)\n",
        "    oob_ls.append(oob_error)\n",
        "  print(\"OOB estimate: {:.2f}\".format(np.mean(oob_ls)))\n",
        "  return tree_ls"
      ],
      "metadata": {
        "id": "YmXZkQI42pok"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#given a input vector we can predict its class given a single tree \n",
        "def single_tree_pred(tree, X):\n",
        "  ft_idx = tree['feature_idx']\n",
        "  if X[ft_idx] <= tree['split_point']:\n",
        "    if type(tree['left_split']) == dict:\n",
        "      return single_tree_pred(tree['left_split'], X)\n",
        "    else:\n",
        "      value = tree['left_split']\n",
        "      return value\n",
        "  else:\n",
        "    if type(tree['right_split']) == dict:\n",
        "      return single_tree_pred(tree['right_split'], X)\n",
        "    else:\n",
        "      return tree['right_split']\n",
        "\n",
        "def predict_rf(tree_ls, X):\n",
        "  pred_ls = list()\n",
        "  for i in range(len(X)):\n",
        "    ensemble_preds = [single_tree_pred(tree, X[i]) for tree in tree_ls]\n",
        "    final_pred = max(ensemble_preds, key = ensemble_preds.count)\n",
        "    pred_ls.append(final_pred)\n",
        "  return np.array(pred_ls)"
      ],
      "metadata": {
        "id": "B7m9_u5A-tdD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Train**"
      ],
      "metadata": {
        "id": "gdwaoKcnAJ9M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_tree = 100\n",
        "max_features = 3\n",
        "max_depth = 10\n",
        "min_samples_split = 2\n",
        "\n",
        "rf = random_forest(X_train, y_train, n_tree, max_features, max_depth, min_samples_split)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jfdZtxBwAONd",
        "outputId": "3b1b2ea4-4ca7-4620-8562-75de2bd05227"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OOB estimate: 0.46\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Test**"
      ],
      "metadata": {
        "id": "E9alYzRTAYmh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "preds = predict_rf(rf, X_test)\n",
        "acc = sum(preds == y_test) / len(y_test)\n",
        "print(\"Testing accuracy: {}\".format(np.round(acc,3)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CMJzODa4AbxM",
        "outputId": "946ac2e7-e944-4845-d831-5f1393410a08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing accuracy: [0.607]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Comparison with the Slearn Random Forest*"
      ],
      "metadata": {
        "id": "WJpGPd85G-i7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "sk_rand_for = RandomForestClassifier(n_estimators=100, max_leaf_nodes=2, n_jobs=-1)\n",
        "#train\n",
        "y_t = y_train.ravel()\n",
        "sk_rand_for.fit(X_train, y_t)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rVTGPI01HDmw",
        "outputId": "81a4d0c6-7c72-4378-b4e4-2fc0224f9436"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(max_leaf_nodes=2, n_jobs=-1)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#test phase\n",
        "y_pred_sk = sk_rand_for.predict(X_test)\n",
        "cm = confusion_matrix(y_test, y_pred_sk)\n",
        "print('Random Forest confusion matrix: \\n', cm)\n",
        "print (\"Accuracy : \", accuracy_score(y_test, y_pred_sk))\n",
        "print(classification_report(y_test, y_pred_sk))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x6I7nvalIRTW",
        "outputId": "6855fd8e-a8ff-40e2-ab47-ec9a25e02e69"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest confusion matrix: \n",
            " [[138  15]\n",
            " [ 27  95]]\n",
            "Accuracy :  0.8472727272727273\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.90      0.87       153\n",
            "           1       0.86      0.78      0.82       122\n",
            "\n",
            "    accuracy                           0.85       275\n",
            "   macro avg       0.85      0.84      0.84       275\n",
            "weighted avg       0.85      0.85      0.85       275\n",
            "\n"
          ]
        }
      ]
    }
  ]
}